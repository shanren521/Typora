### 1.环境安装

```python
'''
安装
onnxruntime-gpu==1.12.0
openvino==2022.3.0
openvino-dev==2022.3.0
opencv-python==4.5.5.64
torch==1.13.1+cu116
torchvision==0.14.1+cu116
onnx==1.12.0
https://github.com/ultralytics/yolov5
'''
```

### 2.模型可视化与精度

```python
'''
yolov5目录下export.py, yolov5s.pt
python export.py --weights yolov5s.pt --include onnx
python detect.py --weights yolov5s.onnx --source data/images/zida
'''
```

### 3.yolov5模型结构

```python
'''
Backbone + Neck + Head
Backbone =CSP
Neck = PANet(双向金字塔)
Head = output(Dense Prediction)
输出信息=[N * C * H * W * (num + 5)]
N图片数量，C通道数，H高，W宽，num是类别数量，5输出识别图像的中心坐标及高宽、score
输入图像：[1 * N * H * W] = [1*3*640*640]
'''
import cv2 as cv
import numpy as np
import time


def build_model():
    # dnn用来加载onnx、tensorflow等模型的方法
    net = cv.dnn.readNet("yolov5s.onnx")
    # DNN_BACKEND_INFERENCE_ENGINE, DNN_BACKEND_CUDA 需要重新编译opencv
    net.setPreferableBackend(cv.dnn.DNN_BACKEND_OPENCV)
    # 使用gpu执行
    net.setPreferableTarget(cv.dnn.DNN_TARGET_CPU)
    return net


INPUT_WIDTH = 640
INPUT_HEIGHT = 640
SCORE_THRESHOLD = 0.2
NMS_THRESHOLD = 0.4
CONFIDENCE_THRESHOLD = 0.4


def detect(image, net):
    # 1*3*640*640
    # 对图像进行预处理， 1/255.0将图像数值转为0-1之间的数(缩放)，swapRB是否进行颜色通道转换(RGB->BGR)
    blob = cv.dnn.blobFromImage(image, 1 / 255.0, (INPUT_WIDTH, INPUT_HEIGHT), swapRB=True, crop=False)
    net.setInput(blob)
    preds = net.forward()
    return preds


def load_capture():
    cap = cv.VideoCapture("D:/videos/Boogie_UP.mp4")
    return cap


def load_classes():
    class_list = []
    with open("classes.txt", "r") as f:
        class_list = [cname.strip() for cname in f.readlines()]
    return class_list


class_list = load_classes()


# 检测后处理
def wrap_detection(input_image, output_data):
    class_ids = []
    confidences = []
    boxes = []
    # 1 * 25200 * 85
    print(output_data.shape)
    rows = output_data.shape[0]

    image_width, image_height, _ = input_image.shape

    # 原图与输入图像的比例
    x_factor = image_width / INPUT_WIDTH
    y_factor = image_height / INPUT_HEIGHT

    for r in range(rows):
        # 85 前5为检测出图像的坐标中心位置，高宽及score，后80为分类
        row = output_data[r]
        confidence = row[4]
        if confidence >= 0.4:
            classes_scores = row[5:]
            _, _, _, max_indx = cv.minMaxLoc(classes_scores)
            class_id = max_indx[1]
            if classes_scores[class_id] > 0.25:
                confidences.append(confidence)
                class_ids.append(class_id)

                x, y, w, h = row[0].item(), row[1].item(), row[2].item(), row[3].item()
                # 得到实际检测出的图像的左上点的坐标  x - 0.5 * w 得到当前输入图像检测出的左上坐标x，然后进行缩放
                left = int(x - 0.5 * w) * x_factor
                top = int(y - 0.5 * w) * y_factor
                width = int(w * x_factor)
                height = int(h * y_factor)
                box = np.array([left, top, width, height])
                boxes.append(box)
    # 非极大抑制函数  3个通道的话会检测出3个框， NMSBoxes会消除检测出的重复的图像，保留最优框
    # 0.25为置信度阈值，0.45为nms阈值，将置信度最高的框与剩下的框求IOU交并比，大于0.45去除, (所有的框的置信度必须大于0.25，否则不参与计算)
    indexes = cv.dnn.NMSBoxes(boxes, confidences, 0.25, 0.45)

    result_class_ids = []
    result_confidences = []
    result_boxes = []
    for i in indexes:
        result_confidences.append(confidences[i])
        result_class_ids.append(class_ids[i])
        result_boxes.append(boxes[i])
    return result_class_ids, result_confidences, result_boxes


# 调整图像大小
def format_yolov5(frame):
    row, col, _ = frame.shape
    _max = max(col, row)
    result = np.zeros((_max, _max, 3), np.uint8)
    result[0:row, 0:col] = frame
    return result

def demo():
    colors = [(255, 255, 0), (0, 255, 0), (0, 255, 255), (255, 0, 0)]
    net = build_model()
    capture = load_capture()
    start = time.time()
    frame_count = 0
    total_frames = 0
    fps = -1

    while True:
        start = time.time()
        ret, frame = capture.read()
        if not ret:
            break
        inputImage = format_yolov5(frame)
        outs = detect(inputImage, net)
        class_ids, confidences, boxes = wrap_detection(inputImage, outs[0])
        frame_count += 1
        total_frames += 1

        for class_id, confidence, box in zip(class_ids, confidences, boxes):
            color = colors[int(class_id) % len(colors)]
            box = box.astype(int)
            cv.rectangle(frame, box, color, 2)
            cv.rectangle(frame, (box[0], box[1] - 20), (box[0] + box[2], box[1]), color, -1)
            cv.putText(frame, class_list[class_id], (box[0], box[1] - 10), cv.FONT_HERSHEY_SIMPLEX, .5, (0, 0, 0))
        end = time.time()
        inf_end = end - start
        fps = 1 / inf_end
        fps_label = "FPS: %.2f" % fps
        cv.putText(frame, fps_label, (10, 25), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
        cv.imshow("output", frame)
        if cv.waitKey(1) > -1:
            break
    print("Total frames: ", str(total_frames))


if __name__ == '__main__':
    # build_model()
    class_list = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',
         'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',
         'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',
         'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',
         'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
         'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',
         'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',
         'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',
         'hair drier', 'toothbrush']
    # with open("classes.txt", "a") as file:
    #     for class_ in class_list:
    #         file.write(class_+"\n")
    demo()
```

### 4.自定义对象检测(基于yolov5)

```python
'''
数据格式转换
VOC XML格式转到YOLO txt格式
VOC XML： x, y, w, h
YOLO txt: center_x, center_y, w, h
# 训练示例命令
python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov5s.pt
# 验证示例命令
python detect.py --weights training/train_best.pt --source D:/train/train_test.mp4
python detect.py --weights training/train_best.pt --source D:/train/test.png --conf-thres
训练数据集目录结构必须遵循下图
'''
```

![image-20230425224203378](D:\learn\Typora\pictures\image-20230425224203378.png)

### 5.YOVOv5个平台部署与推理

```python
'''
模型导出onnx格式
python部署：opencv dnn、onnxruntime、openvino、tensorRT
c++部署：opencv dnn、onnxruntime、openvino、tensorRT
模型导出语句：导出torchscript、onnx两种格式
python export.py --weights training/train_best.pt --include torchscript onnx
测试模型
python detect.py --weights training/train_best.pt --include 
部署平台：
	YOLOv5
	openCV DNN 4.5.4
	onnxruntime-gpu1.7
	openvino2022.1: intel推出，cpu平台加速推理首选
	mo --input_model D:\train\train_best.onnx
	tensorRT8.4: NVIDIA推出针对深度模型部署
nvidia官网下载tensorRT文件
'''
# opencv DNN

# onnxruntime-gpu

# openvino2022

# tensorRT  需要cuda等版本配套
# 下载的tensorRT解压文件夹进入python目录
# pip install tensorrt_8.6.1-cp310-none-win_amd64.whl
# 进入onnx_graphsurgeon安装
# pip install onnx_graphsurgeon-0.3.12-py2.py3-none-any.whl
# 进入uff目录
# pip install uff-0.6.9-py2.py3-none-any.whl
# 进入graphsurgeon目录
# pip install graphsurgeon-0.4.6-py2.py3-none-any.whl
# 将tensorRT的lib目录配置到环境变量
# 将pt模型文件转为engine文件(TensorRT)  时间较长
python export.py --device 0 --weights training/training_best.pt --include torchscript engine
```

