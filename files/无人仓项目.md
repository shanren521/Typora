获取的视频是2D还是3D的？2D的，

人和物体之间的距离小于0.2表示人是携带物体的，那么如果人背后和物体是重叠的怎么解决？

答：人和物体之间的距离小于0.2连续5帧则表示携物出库

### 工业刀片缺陷检测

+ 图像转为灰度图并二值化
+ 对图像进行形态学开操作，填充一些小点
+ 进行轮廓发现，计算轮廓的最小外接矩形并过滤轮廓面积小的轮廓
+ 选取其中较好的轮廓作为模板与其他轮廓对比差异
+ 对差异的图像进行形态学开操作
+ 计算差异图像上像素点的值等于255的个数
+ 如果个数大于50，则认为该刀片是缺陷刀片
+ 在原图像上标记出缺陷的刀片

### 电表检测

+ 生成训练数据集矩阵和标签集矩阵
+ 读取每张图片
+ 将每张图片的大小设置为宽64高为一定比例的图片
+ 将图片转为灰度图
+ 生成一张用来存放原图的矩阵，并将原图放到新图的指定位置
+ 进行HOG特征描述子计算，得到描述子
+ 将描述子存入训练集矩阵，每一行代表一张图像的特征描述子
+ 设置标签集每一行对应的标签，有电表图的设置为1，没有则设置为-1
+ 生成SVM实例对训练集和标签集进行训练，得到xml模型文件
+ 读取模型文件对图片进行开窗检测
+ 行从64开始到-64行，步长为4，列从32开始到-32，步长为4
+ 对要预测的图像进行HOG计算，得到对应每个像素点的特征描述子
+ 使用svm加载训练出来的模型并对得到的特征描述子矩阵进行预测
+ 如果结果大于0，就计算box的宽高和及数量，得出box的平均宽高，并在原图上画出来

### aabdpro

+ 读取告警数据，并过滤读取过程中会报错的行数据，将过滤的行号写入日志中
+ 判断挖掘的类型，查看是增量挖掘还是历史挖掘
+ 
+ 使用networkx库通过基站和机房数据构建topo图
+ 



### 无人仓

+ deepsort+yolov5+reid
+ 基于yolov5进行检测工作台、人、箱子
+ osnet_x0_25进行预训练(reid)   osnet模型用来特征提取
+ 人与工作台重叠的面积和工作台的比值超过阈值0.5则说明人经过了工作台
+ 选择设备，查看GPU是否可用，不可用则用CPU
+ 人与箱子的距离阈值为20个像素点，超过这个阈值则为不携带箱子
+ 人与箱子连续检测5帧以上为携带箱子
+ 人从图像的底部消失连续5帧则判断为出库
+ 读取视频循环视频的每一帧
+ 实例化strongsort对象，包含Reid检测对象，特征提取对象，目标跟踪器对象
+ 对每帧图像进行图像的缩放，(640,640)，并对图像顶部和底部进行填充(letterbox函数)12个像素
+ 原图像为720*1280，最小比例为0.5，缩放后为360\*640，640 - 360 = 280，280 % 32 / 2 = 12
+ 缩放后的真实图像为384\*640，因为模型的stride步长为32所以要对32求余
+ 对图像进行通道转换，cv读取出来的图像为HWC, BGR  而torch需要的为CHW，RGB，并使用numpy的ascontiguousarray转为连续的数组，因为transpose后数组在内存中不连续，影响速度
+ 利用模型对每帧图像进行预测，返回坐标，置信度得分，以及类别
+ 利用nms非最大抑制进行候选框选择，得出最佳的候选框并返回
+ 利用前一帧和当前帧进行目标跟踪，通过osnet模型更新数值，返回新增跟踪id
+ 根据预测出的目标框与当前目标框进行相似度比较，判断是否是同一个目标
+ 通过前一帧与当前帧的矩形框对比出人的移动方向，计算人和箱子的距离是否大于阈值，如果物体下边缘接近底部，就用上边缘判断物体移动方向。
+ 

