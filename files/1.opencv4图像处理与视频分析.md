### 1.图像文件加载和保存

+ ```c++
  #include<opencv2/opencv.hpp>
  #include<iostream>
  
  using namespace cv;
  using namespace std;
  
  int main(int argc, char** argv) {
      // Mat 图像文件的内存数据对象
      // IMREAD_GRAYSCALE 灰度显示 IMREAD_UNCHANGED不改变通道数可以显示透明通道
  	Mat src = imread("D:/project/pyworkspaces/OpenCV-Python-Tutorial-master/data/lena.jpg", IMREAD_UNCHANGED);
  	if (src.empty()) {
  		printf("could not find image file");
  		return -1;
  	}
      // WINDOW_AUTOSIZE 自动适配图像大小，WINDOW_NORMAL可以修改图像大小
  	namedWindow("001-demo", WINDOW_AUTOSIZE);
      // 不支持透明通道
  	imshow("001-demo", src);
      // 保存
      imwrite("D:/project/vsworkspaces/opencv4test/opencv4_001/testlogo.png", src)
  	waitKey(0);
  	destroyAllWindows();
  	return 0;
  }
  ```

### 2.Mat对象的创建和使用

+ ```c++
  Mat src = imread("D:/project/vsworkspaces/opencv_class_data/images/toux.jpg", IMREAD_COLOR);
  // 获取图像的宽度
  int width = src.cols;
  // 获取图像的高度
  int height = src.rows;
  // 获取通道数
  int dim = src.channels();
  // 获取图像深度
  int d = src.depth();
  // 获取图像的类型
  int t = src.type();
  if (t == CV_8UC3) {
      printf("width: %d, height: %d, channels: %d, depth: %d, type: %d\n", width, height, dim, d, t);
  }
  // create Mat one
  // 高度，宽度
  Mat t1 = Mat(256, 256, CV_8UC3);
  // 创建红色对象
  t1 = Scalar(0, 0, 255);
  // create Mat two
  Mat t2 = Mat(Size(512, 512), CV_8UC3);
  t2 = Scalar(255, 0, 255);
  // create Mat three
  Mat t3 = Mat::ones(Size(256, 256), CV_8UC3);
  // create from source
  // 赋值浅拷贝
  Mat t4 = src;
  t4 = Scalar(0, 255, 0);
  // clone深拷贝
  Mat t5 = src.clone();
  // copyTo深拷贝
  Mat t6;
  src.copyTo(t6);
  // 生成和原图大小类型一样的图像
  Mat t7 = Mat::zeros(src.size(), src.type());
  // 遍历与访问像素值
  Mat src1 = imread("D:/project/vsworkspaces/opencv_class_data/images/toux.jpg", IMREAD_COLOR);
  int width1 = src1.cols;
  int height1 = src1.rows;
  int ch = src1.channels();
  /*
  for (int row = 0; row < height1; row++) {
      for (int col = 0; col < width1; col++) {
          if (ch == 3) {
              // Vec3b表示字节, 获取row，col位置对应的像素值
              Vec3b pixel = src1.at<Vec3b>(row, col);
              int blue = pixel[0];
              int green = pixel[1];
              int red = pixel[2];
              src1.at<Vec3b>(row, col)[0] = (255 - blue);
              src1.at<Vec3b>(row, col)[1] = (255 - green);
              src1.at<Vec3b>(row, col)[2] = (255 - red);
          }
          if (ch == 1) {
              int pv = src1.at<uchar>(row, col);
              src1.at<uchar>(row, col) = (255 - pv);
          }
      }
  }
  */
  Mat result = Mat::zeros(src1.size(), src1.type());
  for (int row = 0; row < height1; row++) {
      // 获取当前位置的行
      uchar* curr_row = src1.ptr<uchar>(row);
      uchar* result_row = result.ptr<uchar>(row);
      for (int col = 0; col < width1; col++) {
          if (ch == 3) {
              int blue = *curr_row++;
              int green = *curr_row++;
              int red = *curr_row++;
              *result_row++ = 255 - blue;
              *result_row++ = 255 - green;
              *result_row++ = 255 - red;
          }
          if (ch == 1) {
              int pv = *curr_row++;
              *result_row++ = 255 - pv;
          }
      }
  }
  ```


### 3.图像算术操作

+ ```c++
  string path1 = "D:/learn/opencv/sources/samples/data/WindowsLogo.jpg";
  string path2 = "D:/learn/opencv/sources/samples/data/LinuxLogo.jpg";
  Mat src1 = imread(path1);
  Mat src2 = imread(path2);
  /*
  // 图像相加的结果存入dst中
  Mat dst1;
  add(src1, src2, dst1);
  imshow("add-demo", dst1);
  
  // 图像相减的结果存入dst中
  Mat dst2;
  subtract(src1, src2, dst2);
  imshow("subtract-demo", dst2);
  
  // 图像相乘的结果存入dst中
  Mat dst3;
  multiply(src1, src2, dst3);
  imshow("multiply-demo", dst3);
  
  // 图像相除的结果存入dst中
  Mat dst4;
  divide(src1, src2, dst4);
  imshow("divide-demo", dst4);
  */
  
  Mat src = imread("D:/images/cat.jpg");
  Mat resizeimg;
  // 参数：输入图像，输出图像，缩放后的尺寸(如果为空，后面两个参数指定)，0，0表示输出图像的高宽(前面有指定则默认0)，重新采样时使用的插值方法
  resize(src, resizeimg, Size(src.cols/10, src.rows*0.1), 0, 0, INTER_LINEAR);
  // 生成与cat图像大小类型一样的黑色图像
  Mat black = Mat::zeros(resizeimg.size(), resizeimg.type());
  Mat dst_black;
  Mat dst_light;
  black = Scalar(60, 60, 60);
  // 图像变暗
  subtract(resizeimg, black, dst_black);
  
  // 图像变亮
  add(resizeimg, black, dst_light);
  // 黑色(0,0,0)
  // 白色(255,255,255)
  // 对RGB图像来说，亮度越大值越高
  // 对比度 图像细节信息
  // 改变图像所有像素的权重
  Mat dst2;
  // 参数：原图像，权重，用来在原图上修饰的图像，对比度，bias常量与计算出的像素值相加，输出图像
  addWeighted(resizeimg, 1.2, black, 0.3, 0.0, dst2);
  ```

### 4.图像位操作

+ ```c++
  string path = "D:/project/vsworkspaces/opencv_class_data/images/master.jpg";
  Mat src = imread(path);
  // 图像取反
  Mat m1;
  Mat mask = Mat::zeros(src.size(), CV_8UC1);
  Mat mask2 = Mat::zeros(src.size(), CV_8UC1);
  int w = src.cols / 2;
  int h = src.rows / 2;
  for (int row = 20; row < h-50; row++) {
      for (int col = 150; col < w+150; col++) {
          mask.at<uchar>(row, col) = 255;
          mask2.at<uchar>(row, col) = 50;
  
          }
      }
  // 非操作 参数：原图，输出图，mask  ~1=0，~0=1  
  bitwise_not(src, m1, mask);
  
  // 与操作 1&1=1,1&0=0,0&1=0,0&0=0
  Mat m2;
  bitwise_and(src,src, m2, mask);
  
  // 或操作 1|1=1,1|0=1,0|1=1,0|0=0
  Mat m3;
  bitwise_or(src, src, m3, mask);
  
  // 异或操作 1^1=0, 1^0=1,0^1=1,0^0=0
  Mat m4
  bitwise_xor(src, src, m4, mask);
  ```

### 5.像素信息统计

+ ```c++
  string path = "D:/images/cat1.jpg";
  Mat src = imread(path, IMREAD_GRAYSCALE);
  int w = src.cols;
  int h = src.rows;
  int ch = src.channels();
  printf("w: %d, h: %d, ch: %d", w, h, ch);
  // 获取最大值最小值
  double min_val;
  double max_val;
  Point minloc;
  Point maxloc;
  //minMaxLoc(src, &min_val, &max_val, &minloc, &maxloc);
  //printf("min: %.2f, max: %.2f\n", min_val, max_val);
  // 均值方差
  //Scalar s = mean(src);
  //printf("mean: %.2f, %.2f, %.2f\n",s[0], s[1], s[2]);
  Mat mm, mstd;
  // 均值和标准差
  //meanStdDev(src, mm, mstd);
  //printf("stddev: %.2f, %.2f, %.2f", mstd.at<double>(0, 0), mstd.at<double>(1, 0), mstd.at<double>(2, 0));
  
  // 像素值统计信息
  vector<int>hist(256);  // 创建一个数组
  for (int i = 0; i < 256; i++) {
      hist[i] = 0;
  }
  for (int row = 0; row < h; row++) {
      for (int col = 0; col < w; col++) {
          if (row == 0) {
              int pv = src.at<uchar>(row, col);
              hist[pv]++;
              printf("pv: %d, hist: %d, %d\n", pv, hist, hist[pv]);
          }
      }
  }
  ```

### 6.图形绘制与填充

+ ```c++
  Mat canvas = Mat::zeros(Size(512, 512), CV_8UC3);
  // 图形绘制与填充
  // 画布，坐标1，坐标2，线的颜色，线的粗细，线段的渲染方式(LINE_AA反锯齿)
  line(canvas, Point(10, 10), Point(400, 400), Scalar(0, 0, 255), 1, LINE_AA);
  
  // 绘制长方形
  // (100,100)为长方形的起始位置，200宽,300高
  Rect rect(100, 100, 200, 300);
  rectangle(canvas, rect, Scalar(0, 255, 0), 1, 8);
  // 绘制圆
  // 画布，(200, 300)圆心，100半径，颜色，线的粗细，线的渲染方式
  circle(canvas, Point(200, 300), 100, Scalar(255, 0, 0), 1, 8);
  // 椭圆
  // 椭圆旋转
  RotatedRect rrt;
  rrt.center = Point(200, 200);
  // 旋转角度
  rrt.angle = CV_PI / 4;
  // 椭圆的长轴和短轴长度
  rrt.size = Size(100, 200);
  // 线的粗细值为-1时填充图形
  ellipse(canvas, rrt, Scalar(0, 255, 255), -1, 8);
  // 给图像写入文字信息
  // 待绘制图像，绘制文字，文本框的左下角，字体类型，字体大小，字体颜色，文本厚度，线条类型
  putText(canvas, "hello opencv", Point(100, 50), FONT_HERSHEY_SIMPLEX, 1.0, Scalar(0, 255, 0), 2, 8);
  	
  Mat image = Mat::zeros(Size(512, 512), CV_8UC3);
  int x1 = 0, y1 = 0;
  int x2 = 0, y2 = 0;
  // 定义随机对象
  RNG rng(12345);
  while (true) {
      // 从0-512随机选取值
      x1 = (int)rng.uniform(0, 512);
      x2 = (int)rng.uniform(0, 512);
      y1 = (int)rng.uniform(0, 512);
      y2 = (int)rng.uniform(0, 512);
      int w = abs(x2 - x1);
      int h = abs(y2 - y1);
      rect.x = x1;
      rect.y = y1;
      rect.width = w;
      rect.height = h;
      image = Scalar(0, 0, 0);  // 重新赋值
      //line(image, Point(x1, y1), Point(x2, y2), Scalar(rng.uniform(0, 256), rng.uniform(0, 256), rng.uniform(0, 256)), 1, 8);
      rectangle(image, rect, Scalar(rng.uniform(0, 256), rng.uniform(0, 256), rng.uniform(0, 256)), 1, 8);
      imshow("image", image);
      char c = waitKey(10);
      if (c == 27) {//esc
          break;
      }
  }
  ```
  

### 7.图像通道合并与分离

+ ```c++
  // 一种数据结构，一个类，相当于动态的数组，成为容器
  // 存放的数据类型为Mat，变量为mv
  vector<Mat>mv;
  // 通道分离，图像的通道切分出来存入mv
  split(src, mv);
  int size = mv.size();
  printf("number channels size: \n", size);
  imshow("blue channels", mv[0]);
  imshow("green channels", mv[1]);
  imshow("red channels", mv[2]);
  bitwise_not(mv[0], mv[0]);
  // 给1通道赋值为0
  mv[1] = Scalar(0);
  Mat dst;
  // 合并通道
  merge(mv, dst);
  // ROI  截取图像
  // Rect类，roi对象 用来存储一个矩形框的左上角坐标、宽度和高度
  Rect roi;
  roi.x = 100;
  roi.y = 100;
  roi.width = 250;
  roi.height = 200;
  // clone()深拷贝
  Mat sub = src(roi).clone();
  rectangle(src, roi, Scalar(0, 255, 0), 1, 8);
  imshow("roi", sub);
  // 在原图像上展示截取的位置
  imshow("result", src);
  ```

### 8.图像直方图

+ ```c++
  // 直方图统计与显示、直方图均衡化、直方图比较
  // 计算直方图
  int histSize = 256;
  Mat b_hist, g_hist, r_hist;
  float range[] = { 0, 255 };
  const float* histRanges = { range };
  // 绘制每个通道的直方图
  // 参数：输入的图像，图像的数量，列出通道，掩码(一般不使用), 结果的直方图，结果直方图的维度，bins箱子数量，像数值范围,箱子间的间距是否相同，是否在多次调用时进行累加
  calcHist(&mv[0], 1, 0, Mat(), b_hist, 1, &histSize, &histRanges, true, false);
  calcHist(&mv[1], 1, 0, Mat(), g_hist, 1, &histSize, &histRanges, true, false);
  calcHist(&mv[2], 1, 0, Mat(), r_hist, 1, &histSize, &histRanges, true, false);
  Mat result = Mat::zeros(Size(600, 400), CV_8UC3);
  int margin = 50;
  int h = result.rows;
  int nm = result.rows - 2 * margin;
  // 归一化：将输入数组的数值范围归一到一定范围内
  // 参数：输入图像数组，输出图像数组，范围的最小值，范围的最大值，归一化类型，负数时输出数组的类型与输入数组相同否则只是通道数相同,指定操作的区域或空间
  normalize(b_hist, b_hist, 0, nm, NORM_MINMAX, -1, Mat());
  normalize(g_hist, g_hist, 0, nm, NORM_MINMAX, -1, Mat());
  normalize(r_hist, r_hist, 0, nm, NORM_MINMAX, -1, Mat());
  float step = 500.0 / 256.0;
  for (int i = 0; i < 255; i++) {
      line(result, Point(step * i+50, 50 + nm - b_hist.at<float>(i, 0)), Point(step*(i+1)+50, 50+nm- b_hist.at<float>(i + 1, 0)), Scalar(255, 0, 0),2, 8, 0);
      line(result, Point(step * i+50, 50 + nm - g_hist.at<float>(i, 0)), Point(step*(i+1)+50, 50+nm- g_hist.at<float>(i + 1, 0)), Scalar(0, 255, 0),2, 8, 0);
      line(result, Point(step * i+50, 50 + nm - r_hist.at<float>(i, 0)), Point(step*(i+1)+50, 50+nm- r_hist.at<float>(i + 1, 0)), Scalar(0, 0, 255),2, 8, 0);
  }
  ```


### 9.直方图均衡化(单通道)、比较(单|多通道)

+ ```c++
  /*
  64*64图像，8个bin，8个级别
  像素总数4096
  */
  // 颜色转换，参数：输入图像，输出图像，转换方式
  cvtColor(src, gray, COLOR_BGR2GRAY);
  // 直方图均衡化：让图像的直方图尽可能的平稳
  // 参数：输入图像，输出图像
  equalizeHist(gray, dst);
  /*
  直方图比较
  相关性、卡方、交叉、巴氏距离
  */
  // 归一化
  normalize(hist1, hist1, 0, 1.0, NORM_MINMAX, -1, Mat());
  normalize(hist2, hist2, 0, 1.0, NORM_MINMAX, -1, Mat());
  // 巴氏比较，值越大越不相关
  double h12 = compareHist(hist1, hist2, HISTCMP_BHATTACHARYYA);
  double h11 = compareHist(hist1, hist1, HISTCMP_BHATTACHARYYA);
  printf("h12: %.2f, h11: %.2f\n", h12, h11);
  
  // 相关性比较,值越大越相关
  double c12 = compareHist(hist1, hist2, HISTCMP_CORREL);
  double c11 = compareHist(hist1, hist1, HISTCMP_CORREL);
  printf("c12: %.2f, c11: %.2f\n", c12, c11);
  ```

### 10.图像查找表与颜色表

+ ```c++
  /*
  LUT使用：预计算、查找执行、LUT
  applyColorMap
  */
  Mat dst;
  Mat lut = Mat::zeros(256, 1, CV_8UC3);
  // 对每个通道应用查找表
  LUT(src, lut, dst);
  // 伪彩色变换
  applyColorMap(src, dst, COLORMAP_OCEAN);
  ```

### 11.图像卷积

+ ```c++
  /*
  基本操作
  边缘处理
  卷积核核数 / 2 = 边缘填充的圈数
  边缘填充：
  	BORDER_WRAP
  	BORDER_DEFAULT = BORDER_REFLECT_101
  	BORDER_CONSTANT
  	BORDER_REPLACE
  */
  // Size(3, 3)卷积核，Point指定位置,-1,-1默认锚点为中心位置
  blur(src, dst, Size(3, 3), Point(-1, -1), BORDER_DEFAULT);  // 卷积核越大越模糊
  // 边缘填充 参数：输入，输出，上下左右，填充类型，填充颜色
  copyMakeBorder(src, border_m, border, border, border, border, BORDER_WRAP, Scalar(0, 255, 0));
  ```

### 12.图像模糊

+ ```c++
  /*
  高斯模糊
  盒子模糊
  */
  // 高斯模糊: 输入，输出，滤波器尺寸(卷积核大小)，控制高斯曲线形状的参数
  GaussianBlur(src, dst, Size(15, 15), 15);
  // 盒子模糊, 均值模糊, point设定锚点位置(-1,-1)表示卷积核的中心，true表示归一化， -1表示输出图像的深度
  boxFilter(src, box_dst, -1, Size(5, 5), Point(-1, -1), true, BORDER_DEFAULT);
  ```

### 13.自定义滤波器

+ ```c++
  // 自定义滤波器, 均值卷积
  int k = 15;
  Mat mkernel = Mat::ones(k, k, CV_32F) / (float)(k*k);
  Mat dst;
  // -1表示输出图像的深度，Point表示锚点的位置-1,-1表示卷积核的中心位置
  filter2D(src, dst, -1, mkernel, Point(-1, -1), 0, BORDER_DEFAULT);
  // 自定义滤波器, 非均值卷积
  Mat robot = (Mat_<int>(2, 2) << 1, 0, 0, -1);
  Mat result;
  // 100为delta，卷积后的像素值与delta相加得出最终输出的像素值
  filter2D(src, result, CV_32F, robot, Point(-1, -1), 100, BORDER_DEFAULT);
  // 数据类型转换为8位无符号整型
  convertScaleAbs(result, result);
  ```

### 14.图像梯度

+ ```c++
  /*
  图像卷积的作用：
  	模糊、梯度、边缘、锐化
  常见的梯度算子：
  	Sobel算子
  	Scharr算子
  	robot算子
  	效果：Scharr > Sobel > robot
  */
  // 自定义滤波器, 非均值卷积
  Mat robot_x = (Mat_<int>(2, 2) << 1, 0, 0, -1);
  Mat robot_y = (Mat_<int>(2, 2) << 0, 1, -1, 0);
  Mat grad_x, grad_y;
  // robot算子实现
  filter2D(src, grad_x, CV_32F, robot_x, Point(-1, -1), 0, BORDER_DEFAULT);
  filter2D(src, grad_y, CV_32F, robot_y, Point(-1, -1), 0, BORDER_DEFAULT);
  // 数据类型转换
  convertScaleAbs(grad_x, grad_x);
  convertScaleAbs(grad_y, grad_y);
  Mat result;
  add(grad_x, grad_y, result);
  imshow("robot gradient", result);
  
  // Sobel算子
  Sobel(src, grad_x, CV_32F, 1, 0);
  Sobel(src, grad_y, CV_32F, 0, 1);
  convertScaleAbs(grad_x, grad_x);
  convertScaleAbs(grad_y, grad_y);
  Mat result2;
  //add(grad_x, grad_y, result2);
  addWeighted(grad_x, 0.5, grad_y, 0.5, 0, result2);
  imshow("sobel gradient", result2);
  
  // Scharr算子
  Scharr(src, grad_x, CV_32F, 1, 0);
  Scharr(src, grad_y, CV_32F, 0, 1);
  convertScaleAbs(grad_x, grad_x);
  convertScaleAbs(grad_y, grad_y);
  Mat result3;
  //add(grad_x, grad_y, result2);
  addWeighted(grad_x, 0.5, grad_y, 0.5, 0, result3);
  imshow("scharr gradient", result3);
  ```


### 15.图像边缘发现

+ ```c++
  /*
  二阶导数算子
  	拉普拉斯算子
  	四邻域
  	八邻域
  	拉普拉斯缺点：受噪声影响较大
  图像边缘发现与锐化
  	图像锐化
  USM锐化
  	sharp_image = blur - laplacian
  */
  Mat dst;
  // -1输出图像的深度，3表示卷积核大小，1.0 scale表示缩放比例因子，0 delta与计算出的像素值相加
  Laplacian(src, dst, -1, 3, 1.0, 0, BORDER_DEFAULT);
  imshow("laplacian demo", dst);
  
  // 图像锐化
  Mat sh_op = (Mat_<int>(3,3)<<0,-1,0,
                               -1,5,-1,
                               0,-1,0);
  Mat result;
  filter2D(src, result, CV_32F, sh_op, Point(-1, -1), 0, BORDER_DEFAULT);
  convertScaleAbs(result, result);
  // Unsharpen mask filter  USM锐化
  Mat blur_image;
  Mat usm_image;
  GaussianBlur(src, blur_image, Size(3, 3), 0);
  addWeighted(blur_image, 1.0, dst, -1.0, 0, usm_image);
  ```

### 16.图像噪声

+ ```c++
  /*
  噪声类型
  	椒盐噪声
  	高斯噪声
  	其他噪声
  */
  Mat src_iamge = src.clone();
  // salt and pepper  椒盐噪声
  RNG rng(12345);
  int h = src.rows;
  int w = src.cols;
  int nums = 10000;
  for (int i = 0; i < nums; i++) {
      int x = rng.uniform(0, w);
      int y = rng.uniform(0, h);
      if (i % 2 == 1) {
          src.at<Vec3b>(y, x) = Vec3b(255, 255, 255);
      }
      else {
          src.at<Vec3b>(y, x) = Vec3b(0, 0, 0);
      }
  }
  imshow("salt and pepper noise", src);
  
  // 高斯噪声
  Mat noise = Mat::zeros(src_iamge.size(), src_iamge.type());
  randn(noise, Scalar(15, 10, 25), Scalar(20, 30, 40));
  Mat dst;
  add(src_iamge, noise, dst);
  imshow("gaussian noise", dst);
  ```

### 16.图像去噪声

+ ```c++
  /*
  中值滤波对于椒盐噪声效果较好
  高斯滤波对于高斯噪声效果较好，但是也不是很理想
  */
  // 中值去噪 中值滤波
  Mat median_dst;
  // 5表示卷积核大小
  medianBlur(src, median_dst, 5);
  imshow("median dst", median_dst);
  // 高斯滤波，高斯去噪
  Mat gauss_dst;
  GaussianBlur(src, gauss_dst, Size(5, 5), 0);
  imshow("gauss dst", gauss_dst);
  ```

### 17.边缘保留滤波

+ ```c++
  /*
  EPF滤波
  高斯双边
  	效果一般
  均值迁移
  非局部均值去噪
  	相似像素块，权重较大，不相似的权重较小
  	对高斯噪声效果好，对椒盐噪声效果差
  局部均方差
  */
  // 双边  参数：0在过滤过程中每个像素邻域的直径范围，100颜色空间过滤器sigma值，坐标空间中滤波器的sigma值
  bilateralFilter(src, dst, 0, 100, 10);
  imshow("bilateral demo", dst);
  // 非局部均值去噪彩色版
  // 参数：输入，输出，过滤器强度h值高可以很好的去除噪声，hcolor作用于彩色图像
  fastNlMeansDenoisingColored(src, dst, 3, 3, 7, 21);
  imshow("NLM color demo", dst);
  
  Mat gray, nim_dst;
  // 非局部均值去噪灰色版
  cvtColor(src, gray, COLOR_BGR2GRAY);
  fastNlMeansDenoising(gray, nim_dst, 15, 10, 30);
  imshow("NLM gray demo", nim_dst);
  ```


### 18.边缘提取

+ ```c++
  /*
  边缘定义：
  	边缘法线：单位向量在该方向上图像像素强度变化最大
  	边缘方向：与边缘法线垂直的向量方向
  	边缘位置或者中心-图像边缘所在位置
  	边缘强度：跟沿法线方向的图像局部对比相关，对比越大，越是边缘
  边缘检测类型与步骤：
  	1.高斯模糊
  	2.基于梯度提取边缘
  		Robert算子
  		Sobel算子
  		Prewitt算子
  		X方向与y方向梯度计算：L = |Gx| + |Gy|
  Canny边缘提取
  	灰度图像
  	模糊去噪声- 高斯模糊
  	提取梯度与方向-Sobel算子
  	非最大信号抑制
  		大于高阈值T1的全部保留
  		小于低阈值T2的全部丢弃
  		在T1-T2之间的，可以链接到高阈值的保留，否则丢弃
  	高低阈值链接
  	边缘输出
  */
  int t1 = 50;
  Mat src;
  void canny_demo(int, void*) {
  	Mat edges, dst;
  	// Canny 边缘提取 参数：输入，输出，低阈值，高阈值
  	Canny(src, edges,t1,t1*3);
  	bitwise_and(src, src, dst, edges);
  	imshow("edges", dst);
  }
  // 通过bar控制参数
  createTrackbar("threshold value:", "input", &t1, 100, canny_demo);
  canny_demo(0, 0);
  ```

### 19.二值图像

+ ```c++
  /*
  灰度图像 - 单通道， 取值范围0~255
  二值图像 - 单通道， 取值0(黑色)和255(白色)
  	二值图像分割：阈值T
  		THRESH_BINARY	大于T 255 else 0
  		THRESH_BINARY_INV	小于T 255 else 0
  		THRESH_TRUNC	小于T 保持原值 else T
  		THRESH_TOZERO	小于T 0 else 原值
  		THRESH_TOZERO_INV	大于T 0 else 原值
  */
  Mat gray, binary;
  cvtColor(src, gray, COLOR_BGR2GRAY);
  // 图像二值化
  // 参数：输入单通道，输出单通道，阈值，最大值，二值化方式
  threshold(gray, binary, 127, 255, THRESH_BINARY);
  
  threshold(gray, binary, 127, 255, THRESH_BINARY_INV);
  
  threshold(gray, binary, 127, 255, THRESH_TOZERO);
  
  threshold(gray, binary, 127, 255, THRESH_TOZERO_INV);
  
  threshold(gray, binary, 127, 255, THRESH_TRUNC);
  ```

### 20.全局阈值

+ ```c++
  /*
  OTSU阈值  双峰图效果好
  三角阈值   单峰图效果好
  */
  // t1, t2是返回的阈值
  double t1 = threshold(gray, binary, 0, 255, THRESH_OTSU);
  double t2 = threshold(gray, binary, 0, 255, THRESH_TRIANGLE);
  printf("OTSU t1: %.2f, TRIANGLE: %.2f", t1, t2);
  ```

### 21.自适应阈值

+ ```c++
  /*
  自适应均值
  	全局阈值对光照不均匀的图像效果较差
  	自适应对不均匀图像求差值，二值化
  	T = S - D + 255
  	盒子模糊图像 -> D   窗口大小Block
  	原图+偏置常量C-> S  常量C
  	ADAPTIVE_THRESH_GAUSSIAN_C
  	ADAPTIVE_THRESH_MEAN_C
  */
  // 25为块的大小，10为使用的阈值
  adaptiveThreshold(gray, binary, 255, ADAPTIVE_THRESH_GAUSSIAN_C, THRESH_BINARY, 25, 10);
  
  adaptiveThreshold(gray, binary, 255, ADAPTIVE_THRESH_MEAN_C, THRESH_BINARY, 25, 10);
  ```


### 22.CCL联通组件

+ ```c++
  /*
  图像连通组件
  四邻域和八邻域连通组件
  块扫描
  两步法扫描
  */
  void ccl_stats_demo(Mat& image) {
  	Mat labels = Mat::zeros(image.size(), CV_32S);
  	Mat stats, centroids;
  	RNG rng(12345);
  	// 连通组件 返回所有连通域的数目
      // 参数：输入二值图像，labels图像上每一像素的标记，8连通，类型，连通方式
  	int num_labels = connectedComponents(image, labels, 8, CV_32S, CCL_DEFAULT);
  	// 参数：stats每一个标记的统计信息，是一个5列矩阵，每个连通区域的外接矩形的x，y，width，height，centroids连通域的中心点
      connectedComponentsWithStats(image, labels, stats, centroids, 8, CV_32S, CCL_DEFAULT);
  	
  	vector<Vec3b>colorTable(num_labels);
  	// background color
  	colorTable[0] = Vec3b(0, 0, 0);
  	for (int i = 0; i < num_labels; i++) {
  		colorTable[i] = Vec3b(rng.uniform(0, 256), rng.uniform(0, 256), rng.uniform(0, 256));
  	}
  	Mat result1= Mat::zeros(image.size(), CV_8UC3);
  	int w = result1.cols;
  	int h = result1.rows;
  	for (int row = 0; row < h; row++) {
  		for (int col = 0; col < w; col++) {
  			int label = labels.at<int>(row, col);
  			result1.at<Vec3b>(row, col) = colorTable[label];
  		}
  	}
  	for (int i = 0; i < num_labels; i++) {
  			// center
  			int cx = centroids.at<double>(i, 0);
  			int cy = centroids.at<double>(i, 1);
  			// 外接矩形、面积
  			int x = stats.at<int>(i, CC_STAT_LEFT);
  			int y = stats.at<int>(i, CC_STAT_TOP);
  			int width = stats.at<int>(i, CC_STAT_WIDTH);
  			int height = stats.at<int>(i, CC_STAT_HEIGHT);
  			int area = stats.at<int>(i, CC_STAT_AREA);
  
  			// 绘制
  			circle(result1, Point(cx, cy), 3, Scalar(0, 0, 255), 2, 8, 0);
  			Rect box(x, y, width, height);
  			rectangle(result1, box, Scalar(0, 255, 0), 2, 8);
  			putText(result1, format("area1: %d", area), Point(x, y), FONT_HERSHEY_PLAIN, 1.0, Scalar(0, 255, 0), 1);
  
  	}
  	putText(result1, format("number1: %d", num_labels - 1), Point(20, 20), FONT_HERSHEY_COMPLEX, 1.0, Scalar(0, 255, 0), 1);
  	printf("total labels1: %d\n", (num_labels - 1));
  	imshow("CCL demo1", result1);
  }
  ```

### 23.图像轮廓

+ ```c++
  /*
  轮廓发现
      图像轮廓 - 图像边界
      主要针对二值图像，轮廓是一系列点的集合
  轮廓计算面积、周长	
  */
  vector<vector<Point>>contours;
  vector<Vec4i>hirearchy;
  // 寻找轮廓
  // 参数：输入二值图像，输出轮廓点集，轮廓的层次结构，轮廓的检索模式，轮廓表示方法
  findContours(binary, contours, hirearchy, RETR_TREE, CHAIN_APPROX_SIMPLE, Point());
  for (size_t t = 0; t < contours.size(); t++) {
      // 计算轮廓的面积
      double area = contourArea(contours[t]);
      // 计算轮廓的周长
      double size = arcLength(contours[t], true);
      if (area > 200) {
          // 找到轮廓的最小外接矩形
          Rect box = boundingRect(contours[t]);
          rectangle(src, box, Scalar(255, 0, 0), 2, 8, 0);
          // 找到轮廓的最小外接斜矩形的四个点  
          // 返回: (center(x,y), (width, height), angle of rotation )
          RotatedRect rrt = minAreaRect(contours[t]);
          ellipse(src, rrt, Scalar(0, 0, 255), 2, 8);
          // point数组
          Point2f pts[4];
          // 将斜矩形的四个点放入数组
          rrt.points(pts);
          // 画矩形
          for (int i = 0; i < 4; i++) {
              line(src, pts[i], pts[(i + 1) % 4], Scalar(0, 0, 255), 2, 8);
          }
          // 画出轮廓，t为-1时画出全部轮廓
          drawContours(src, contours, t, Scalar(0, 255, 0), 2, 8);
      }
  ```

### 24.轮廓匹配

+ ```c++
  /*
  几何矩计算
  Hu矩计算与不变性
  */
  void contour_info(Mat& image, vector<vector<Point>>& contours) {
  	Mat dst;
  	// 二值化
  	GaussianBlur(image, dst, Size(3, 3), 0);
  	Mat gray, binary;
  	cvtColor(dst, gray, COLOR_BGR2GRAY);
  	threshold(gray, binary, 0, 255, THRESH_BINARY_INV | THRESH_OTSU);
  	imshow(format("thresh binary %d", n), binary);
  	n++;
  	vector<Vec4i>hirearchy;
  	// 寻找轮廓,
  	findContours(binary, contours, hirearchy, RETR_EXTERNAL, CHAIN_APPROX_SIMPLE, Point());
  }
  vector<vector<Point>>contours1;
  vector<vector<Point>>contours2;
  contour_info(src, contours1);
  contour_info(src1, contours2);
  // 计算轮廓矩
  Moments mm2 = moments(contours2[0]);
  Mat hu2;
  // Hu不变矩
  HuMoments(mm2, hu2);
  for (size_t t = 0; t < contours1.size(); t++) {
      Moments mm = moments(contours1[t]);
      // 求质心
      double cx = mm.m10 / mm.m00;
      double cy = mm.m01 / mm.m00;
      // 面积 area = m00
      printf("cx: %.2f, cy: %.2f\n", cx, cy);
      circle(src, Point(cx, cy), 3, Scalar(0, 0, 255), 2, 8, 0);
      Mat hu;
      HuMoments(mm, hu);
      // 二值匹配 度量两个轮廓之间的相似度
      double dist = matchShapes(hu, hu2, CONTOURS_MATCH_I1, 0);
      if (dist < 1.0) {
          printf("matched distance value: %.2f\n", dist);
          drawContours(src, contours1, t, Scalar(0, 0, 255), 2, 8);
      }
  }
  ```
  

### 25.轮廓逼近与拟合

+ ```c++
  /*
  轮廓逼近：本质是减少编码点
  拟合：生成最相似的圆或椭圆
  */
  // 轮廓逼近与拟合
  void contours_and_fit(Mat &src) {
  	// 高斯去噪
  	GaussianBlur(src, src, Size(3, 3), 0);
  	Mat gray, binary;
  	// 颜色转换
  	cvtColor(src, gray, COLOR_BGR2GRAY);
  	// 二值化
  	threshold(gray, binary, 0, 255, THRESH_BINARY | THRESH_OTSU);
  	imshow("threshold", binary);
  	// 轮廓发现
  	vector<vector<Point>>contours;
  	vector<Vec4i>hireachy;
  	findContours(binary, contours, hireachy, RETR_EXTERNAL, CHAIN_APPROX_SIMPLE, Point());
  	// 多边形逼近
  	for (size_t t = 0; t < contours.size(); t++) {
  		// 获取中心点的位置
  		Moments mm = moments(contours[t]);
  		double cx = mm.m10 / mm.m00;
  		double cy = mm.m01 / mm.m00;
  		circle(src, Point(cx, cy), 3, Scalar(255, 255, 0), 2, 8, 0);
  
  		// 求面积
  		double area = contourArea(contours[t]);
  		// 求周长, true表示轮廓是封闭的
  		double clen = arcLength(contours[t], true);
  
  		Mat result;
          // 对指定的点集进行逼近, 4表示指定的精度，也即是原始曲线与近似曲线之间的最大距离，true表示近似曲线是闭合的
  		approxPolyDP(contours[t], result, 4, true);
  		printf("corners: %d, columns: %d, area: %.2f, arcLength: %.2f\n", result.rows, result.cols, area, clen);
  		if (result.rows == 6) {
  			putText(src, "poly", Point(cx, cy - 10), FONT_HERSHEY_PLAIN, 1.0, Scalar(0, 0, 255), 1, 8);
  		}
  		if (result.rows == 16) {
  			putText(src, "circle", Point(cx, cy - 10), FONT_HERSHEY_PLAIN, 1.0, Scalar(0, 255, 0), 1, 8);
  		}
  		if (result.rows == 4) {
  			putText(src, "rectangle", Point(cx, cy - 10), FONT_HERSHEY_PLAIN, 1.0, Scalar(0, 255, 255), 1, 8);
  		}
  		if (result.rows == 3) {
  			putText(src, "triangle", Point(cx, cy - 10), FONT_HERSHEY_PLAIN, 1.0, Scalar(255, 0, 255), 1, 8);
  		}
  	}
  }
  // 拟合圆或椭圆
  void fit_func(Mat& src) {
  	// 高斯去噪
  	GaussianBlur(src, src, Size(3, 3), 0);
  	Mat gray, binary;
  	// 颜色转换
  	cvtColor(src, gray, COLOR_BGR2GRAY);
  	// 二值化
  	threshold(gray, binary, 0, 255, THRESH_BINARY | THRESH_OTSU);
  	imshow("threshold", binary);
  	// 轮廓发现
  	vector<vector<Point>>contours;
  	vector<Vec4i>hireachy;
  	findContours(binary, contours, hireachy, RETR_EXTERNAL, CHAIN_APPROX_SIMPLE, Point());
  	// 多边形逼近
  	for (size_t t = 0; t < contours.size(); t++) {
  		drawContours(src, contours, t, Scalar(255, 0, 255), 2, 8);
          // 在二维点集上拟合一个椭圆，返回一个旋转的矩形
  		RotatedRect rrt = fitEllipse(contours[t]);
  		float w = rrt.size.width;
  		float h = rrt.size.height;
  		Point center = rrt.center;
  		circle(src, center, 5, Scalar(0, 255, 0), 2, 8, 0);
  		ellipse(src, rrt, Scalar(255, 255, 0), 2, 8);
  	}
  	imshow("draw Contours", src);
  }
  ```

### 26.霍夫直线检测

+ ```c++
  /*
  噪声影响较大
  HoughLines 极坐标空间参数vector(p, θ)
  HoughLineP()
  */
  void hough_func(Mat& src) {
  	GaussianBlur(src, src, Size(3, 3), 0);
  	Mat gray, binary;
  	cvtColor(src, gray, COLOR_BGR2GRAY);
  	threshold(gray, binary, 0, 255, THRESH_BINARY | THRESH_OTSU);
  	imshow("binary", binary);
  
  	// 霍夫检测
  	vector<Vec3f>lines;
      // 输入二值图像，输出Vec2f类型元素组成的向量(roi,theta)，半径步长，角度步长，最低投票数(高于这个数的直线才会被检测到)
  	HoughLines(binary, lines, 1, CV_PI / 180, 100, 0, 0);
  	// 绘制直线
  	Point pt1, pt2;
  	for (size_t t = 0; t < lines.size(); t++) {
  		float rho = lines[t][0]; // 半径距离
  		float theta = lines[t][1]; // 角度
  		float acc = lines[t][2]; // 累加值
  		printf("rho: %.2f, theta: %.2f, acc: %.2f\n", rho, theta, acc);
  		double a = cos(theta);
  		double b = sin(theta);
  		double x0 = a * rho, y0 = b * rho;
  		pt1.x = cvRound(x0 + 1000 * (-b));
  		pt1.y = cvRound(y0 + 1000 * a);
  		pt2.x = cvRound(x0 - 1000 * (-b));
  		pt2.y = cvRound(y0 - 1000 * a);
  		int angle = round(theta / CV_PI * 180);
  		if (rho > 0) { // 右倾
  			line(src, pt1, pt2, Scalar(0, 255, 255), 1, 8, 0);
  			if (angle == 90) { // 水平线
  				line(src, pt1, pt2, Scalar(255, 0, 255), 2, 8, 0);
  			}
  			if (angle < 1) {// 垂直线
  				line(src, pt1, pt2, Scalar(200, 100, 250), 4, 8, 0);
  			}
  		}
  		else {// 左倾
  			line(src, pt1, pt2, Scalar(255, 255, 0), 2, 8, 0);
  		}
  	}
  	imshow("hough line detection", src);
  }
  void houghP_func(Mat& src) {
  	Mat binary;
  	Canny(src, binary, 80, 160, 3, false);
  	imshow("binary", binary);
  	vector<Vec4i>lines;
      // 输入8位单通道的二值图像，输出矢量(包含起始点和结束点)，半径步长，角度步长，累加阈值，最低线段长度，允许将同一行点与点之间连接起来的最大的距离
  	HoughLinesP(binary, lines, 1, CV_PI / 180, 80, 30, 10);
  	Mat result = Mat::zeros(src.size(), src.type());
  	for (int i = 0; i < lines.size(); i++) {
  		line(result, Point(lines[i][0], lines[i][1]), Point(lines[i][2], lines[i][3]), Scalar(0, 0, 255), 2, 8);
  	}
  	imshow("hough line P", result);
  }
  ```
  

### 27.霍夫圆检测

+ ```c++
  /*
  噪声影响较大
  圆在平面坐标有三个参数决定(x0,y0,r)
  圆的参数方程
  	x = x0 + rcos(θ)
  	y = y0 + rsin(θ)
  */
  //霍夫圆检测
  void hough_circle(Mat& src) {
  	Mat gray;
  	cvtColor(src, gray, COLOR_BGR2GRAY);
  	imshow("gray", gray);
  	
  	// 降噪
  	GaussianBlur(gray, gray, Size(9, 9), 2, 2);
  	vector<Vec3f>circles;
  	double minDist = 15;
  	double min_radius = 10;
  	double max_radius = 50;
      // 40，canny阈值，30，累加阈值, 1.5，分辨率比例
  	HoughCircles(gray, circles, HOUGH_GRADIENT, 1.5, minDist, 40, 30, min_radius, max_radius);
  	for (size_t t = 0; t < circles.size(); t++) {
  		Point center(circles[t][0], circles[t][1]);
  		int radius = round(circles[t][2]);
  		// 绘制圆
  		circle(src, center, radius, Scalar(255, 100, 255), 2, 8, 0);
  		circle(src, center, 2, Scalar(255, 255, 0), 2, 8, 0);
  	}
  	imshow("hough circle", src);
  }
  ```

### 28.图像形态学操作

+ ```c++
  /*
  腐蚀与膨胀
  	膨胀：九宫格最大值替换中心点的值
  	腐蚀：最小值替换中心点的值
  开闭操作
  	开操作：删除小的干扰块, 先腐蚀在膨胀，黑底白点消除白点
  	闭操作：删除小的干扰块，填充闭合区域，先膨胀再腐蚀，白底黑点消除黑点
  形态学梯度
  	基本梯度：膨胀减去腐蚀之后的结果
  	内梯度：原图减去腐蚀之后的结果
  	外梯度：膨胀减去原图的结果
  顶帽与黑帽：用来提取图像中微小有用信息块
  	顶帽：原图减去开操作的结果
  	黑帽：闭操作减去原图的结果
  击中与击不中
  */
  void erode_dilate() {
  	Mat src = imread("D:/images/face_beauty_test.jpg");
  	Mat gray, binary;
  	cvtColor(src, gray, COLOR_BGR2GRAY);
  	threshold(gray, binary, 0, 255, THRESH_BINARY | THRESH_OTSU);
  	imshow("binary", src);
  	// 获取像素元素: 设定卷聚核的形状，卷积核大小，锚点的位置一般为中心点
  	Mat kernel = getStructuringElement(MORPH_RECT, Size(5, 5), Point(-1, -1));
  	
  	Mat outerode, outdilate;
  	// 腐蚀
  	erode(src, outerode, kernel);
  	imshow("erode", outerode);
  	// 膨胀
  	dilate(src, outdilate, kernel);
  	imshow("dilate", outdilate);
  	waitKey(0);
  	destroyAllWindows();
  }
  
  void open_close() {
  	Mat src = imread("D:/images/fill.png");
  	imshow("input", src);
  	Mat gray, binary;
  	cvtColor(src, gray, COLOR_BGR2GRAY);
  	threshold(gray, binary, 0, 255, THRESH_BINARY | THRESH_OTSU);
  
  	Mat kernel = getStructuringElement(MORPH_RECT, Size(15, 1), Point(-1, -1));
  	Mat opens, closes;
  	// 开操作, 1表示迭代次数
  	morphologyEx(binary, opens, MORPH_OPEN, kernel, Point(-1, -1), 1);
  	imshow("opens", opens);
      // 闭操作
  	morphologyEx(binary, closes, MORPH_CLOSE, kernel, Point(-1, -1), 1);
  	imshow("closes", closes);
  	waitKey(0);
  	destroyAllWindows();
  }
  // 形态学梯度
  cvtColor(src, gray, COLOR_BGR2GRAY);
  imshow("input", gray);
  Mat basic_grad, inter_grad, exter_grad;
  Mat kernel = getStructuringElement(MORPH_RECT, Size(3, 3), Point(-1, -1));
  // 基本梯度
  morphologyEx(gray, basic_grad, MORPH_GRADIENT, kernel, Point(-1, -1));
  imshow("basic gradient", basic_grad);
  
  Mat erodeout, dilateout;
  erode(gray, erodeout, kernel);
  dilate(gray, dilateout, kernel);
  // 内梯度
  subtract(gray, erodeout, inter_grad);
  // 外梯度
  subtract(dilateout, gray, exter_grad);
  imshow("inter_grad", inter_grad);
  imshow("exter_grad", exter_grad);
  //图像二值化
  threshold(basic_grad, binary, 0, 255, THRESH_BINARY | THRESH_OTSU);
  imshow("binary", binary);
  
  // 形态学顶帽与黑帽
  void top_black_hat() {
  	Mat src = imread("D:/images/cross.png");
  	Mat gray, binary;
  	cvtColor(src, gray, COLOR_BGR2GRAY);
  	threshold(gray, binary, 0, 255, THRESH_BINARY_INV | THRESH_OTSU);
  	imshow("input", binary);
  
  	Mat k = getStructuringElement(MORPH_ELLIPSE, Size(15, 15), Point(-1, -1));
  	// 顶帽操作
  	Mat tophat;
  	morphologyEx(binary, tophat, MORPH_TOPHAT, k);
  	imshow("tophat", tophat);
  	// 黑帽操作
  	Mat blackhat;
  	morphologyEx(binary, blackhat, MORPH_BLACKHAT, k);
  	imshow("blackhat", blackhat);
  
  	// 击中
  	Mat hitmiss;
  	Mat k1 = getStructuringElement(MORPH_CROSS, Size(15, 15), Point(-1, -1));
  	morphologyEx(binary, hitmiss, MORPH_HITMISS, k1);
  	imshow("hitmiss", hitmiss);
  	waitKey(0);
  	destroyAllWindows();
  }
  ```

### 29.示例

+ ```c++
  /*
  提取星云最大面积
  */
  void example() {
  	string path = "D:/images/case6.jpg";
  	Mat src = imread(path);
  	if (src.empty()) {
  		printf("could not find image file");
  	}
  	namedWindow("input", WINDOW_AUTOSIZE);
  	imshow("input", src);
  
  	// 高斯去噪
  	GaussianBlur(src, src, Size(3, 3), 0);
  	Mat gray, binary;
  	// 颜色转换
  	cvtColor(src, gray, COLOR_BGR2GRAY);
  	// 图像二值化
  	threshold(gray, binary, 0, 255, THRESH_BINARY | THRESH_OTSU);
  	imshow("binary", binary);
  
  	// 开操作
  	Mat se = getStructuringElement(MORPH_RECT, Size(15, 15), Point(-1, -1));
  	morphologyEx(binary, binary, MORPH_CLOSE, se);
  	imshow("close morph", binary);
  	
  	// 轮廓发现
  	int height = binary.rows;
  	int width = binary.cols;
  	vector<vector<Point>>contours;
  	vector<Vec4i>hirearchy;
  	findContours(binary, contours, hirearchy, RETR_EXTERNAL, CHAIN_APPROX_SIMPLE, Point());
  	double max_areas = -1;
  	int cindex = -1;
  	for (size_t t = 0; t < contours.size(); t++) {
  		Rect rect = boundingRect(contours[t]);
  		if (rect.height >= height || rect.width >= width) {
  			continue;
  		}
  		double area = contourArea(contours[t]);
  		double len = arcLength(contours[t], true);
  		if (area > max_areas) {
  			max_areas = area;
  			cindex = t;
  		}
  	}
  	//绘制轮廓
  	drawContours(src, contours, cindex, Scalar(100, 150, 200), 2, 8);
  	// 多边形逼近
  	Mat pts;
  	approxPolyDP(contours[cindex], pts, 2, true);
  	Mat result = Mat::zeros(src.size(), src.type());
  	drawContours(result, contours, cindex, Scalar(100, 150, 200), 2, 8);
  	for (int i = 0; i < pts.rows; i++) {
  		Vec2i pt = pts.at<Vec2i>(i, 0);
          // 绘制圆
  		circle(src, Point(pt[0], pt[1]), 2, Scalar(50, 200, 100), 2, 8, 0);
  		circle(result, Point(pt[0], pt[1]), 2, Scalar(50, 200, 100), 2, 8, 0);
  	}
  	printf("area: %.2f\n", max_areas);
  	imshow("output", src);
  	imshow("result contours analysis", result);
  	waitKey(0);
  	destroyAllWindows();
  }
  ```


### 30.视频读写

+ ```c++
  /*
  支持视频文件、摄像头、视频流
  */
  VideoCapture capture(0);
  //VideoCapture capture("D:/images/vtest.avi");
  if (capture.isOpened()) {
      printf("could not open the camera...\n");
  }
  namedWindow("frame", WINDOW_AUTOSIZE);
  // 获取每秒播放的帧数
  int fps = capture.get(CAP_PROP_FPS);
  // 获取每帧图像的宽度
  int width = capture.get(CAP_PROP_FRAME_WIDTH);
  // 获取每帧图像的高度
  int height = capture.get(CAP_PROP_FRAME_HEIGHT);
  // 获取视频的总帧数
  int total_frames = capture.get(CAP_PROP_FRAME_COUNT);
  // 获取视频类型
  int type = capture.get(CAP_PROP_FOURCC);
  printf("fps: %d, total frames: %d, size(width:%d, height:%d)\n", fps, total_frames, width, height);
  Mat frame;
  // 创建写视频对象, 限制大小2G
  VideoWriter writer("D:/test.mp4", type, fps, Size(width, height), true);
  while (true) {
      bool ret = capture.read(frame);
      if (!ret) break;
      imshow("frame", frame);
      // 保存每帧到本地
      writer.write(frame);
      char c = waitKey(1);
      if (c == 27) {//esc
          break;
      }
  }
  // 释放对象
  capture.release();
  writer.release();
  ```

### 31.图像色彩空间转换

+ ```c++
  /*
  RGB色彩空间
  HSV色彩空间
  Lab色彩空间
  YCbCr色彩空间
  */
  Mat frame, hsv, lab;
  Mat mask, result;
  // 颜色转换
  // HSV :0-180,0-255,0-255
  cvtColor(frame, hsv, COLOR_BGR2HSV);
  //cvtColor(frame, lab, COLOR_BGR2Lab);
  imshow("frame", frame);
  imshow("hsv", hsv);
  //imshow("lab", lab);
  // 提取一定颜色范围内的图像，提取图像, 抠图
  inRange(hsv, Scalar(25, 43, 46), Scalar(77, 255, 255), mask);
  // 取反,使mask前景黑色和背景白色转换
  bitwise_not(mask, mask);
  // 与原图与操作
  bitwise_and(frame, frame, result, mask);
  imshow("mask", mask);
  imshow("result", result);
  ```

### 32.直方图反向投影

+ ```c++
  /*
  给定一个图像，从另一个图像中找出与它相似的部分
  也可以用来检测图像中是否存在另一个图像
  原理：
  	计算直方图
  	计算比率
  	卷积模糊
  	反向输出
  */
  Mat model_hsv, image_hsv;
  cvtColor(model, model_hsv, COLOR_BGR2HSV);
  cvtColor(src, image_hsv, COLOR_BGR2HSV);
  
  int h_bins = 32, s_bins = 32;
  int histSize[] = { h_bins, s_bins };
  int channels[] = { 0, 1 };
  Mat roiHist;
  float h_range[] = { 0, 180 };
  float s_range[] = { 0, 255 };
  const float* ranges[] = { h_range, s_range };
  // 直方图计算
  calcHist(&model_hsv,1, channels, Mat(), roiHist, 2, histSize, ranges, true, false);
  // 归一化处理
  normalize(roiHist, roiHist, 0, 255, NORM_MINMAX, -1, Mat());
  MatND backproj;
  // 反向投影: 1表示一幅图像，用到的通道，需要反向投影的直方图，输出结果，值得范围，1.0选用的换算系数
  calcBackProject(&image_hsv, 1, channels, roiHist, backproj, ranges, 1.0);
  ```

### 33.图像角点检测

+ ```c++
  /*
  角点：在x方向与y方向都有最大的梯度变化的像素点
  在连续的图像移动或拼接中，都要求来检测角点作为特征点
  Harris角点检测
  Shi-tomasi角点检测
  */
  void harris_demo(Mat &src) {
  	Mat gray;
  	cvtColor(src, gray, COLOR_BGR2GRAY);
  	Mat dst;
  	double k = 0.04;
  	int blocksize = 2;
  	int ksize = 3;
  	// 角点检测：blocksize邻域的大小，Sobel核的大小，k检测器的自由参数
  	cornerHarris(gray, dst,blocksize, ksize, k);
  	Mat dst_norm = Mat::zeros(dst.size(), dst.type());
  	// 归一化
  	normalize(dst, dst_norm, 0, 255, NORM_MINMAX, -1, Mat());
  	// 数据类型转换为8位无符号整型
  	convertScaleAbs(dst_norm, dst_norm);
  
  	// 绘制角点
  	RNG rng(12345);
  	for (int row = 0; row < src.rows; row++) {
  		for (int col = 0; col < src.cols; col++) {
  			int rsp = dst_norm.at<uchar>(row, col);
  			if (rsp > 150) {
  				int b = rng.uniform(0, 255);
  				int g = rng.uniform(0, 255);
  				int r = rng.uniform(0, 255);
  				circle(src, Point(col, row), 5, Scalar(b, g, r), 2, 8, 0);
  			}
  		}
  	}
  }
  
  void tomasi_demo(Mat &src) {
  	Mat gray;
  	cvtColor(src, gray, COLOR_BGR2GRAY);
  	vector<Point2f>corners;
  	// tomasi角点检测: gray输入的单通道图像，corners输出检测到的特征点，特征点的最大数量，质量等级，角点间的最小距离，指定区域mask，角点检测需要的k值，是否使用harris角点检测, false为shi-tomasi
  	goodFeaturesToTrack(gray, corners, 200, 0.01, 3, Mat(), 3, false);
  	RNG rng(12345);
  	for (int i = 0; i < corners.size(); i++) {
  		int b = rng.uniform(0, 255);
  		int g = rng.uniform(0, 255);
  		int r = rng.uniform(0, 255);
  		circle(src, corners[i], 5, Scalar(b, g, r), 2, 8, 0);
  		
  	}
  }
  ```


### 34.基于颜色的对象跟踪

+ ```c++
  /*
  色彩空间转换
  视频帧分析与提取
  */
  void process_frame() {
  	VideoCapture capture("D:/images/mulballs.mp4");
  	Mat frame;
  	while (true) {
  		bool ret = capture.read(frame);
  		if (!ret)break;
  		Mat hsv, mask;
  		cvtColor(frame, hsv, COLOR_BGR2HSV);
  		imshow("hsv", hsv);
  		inRange(hsv, Scalar(35, 43, 46), Scalar(77, 255, 255), mask);
  		Mat se = getStructuringElement(MORPH_RECT, Size(15, 15));
  		// 开操作
  		morphologyEx(mask, mask, MORPH_OPEN, se);
  		imshow("result", mask);
  		
  		vector<vector<Point>>contours;
  		vector<Vec4i>hirearchy;
  		findContours(mask, contours, hirearchy, RETR_EXTERNAL, CHAIN_APPROX_SIMPLE, Point());
  		int index = -1;
  		double max_area = 0;
  		for (size_t t = 0; t < contours.size(); t++) {
  			double area = contourArea(contours[t]);
  			double len = arcLength(contours[t], true);
  			if (area > max_area) {
  				max_area = area;
  				index = t;
  			}
  		}
  		// 进行轮廓拟合输出
  		if (index >= 0) {
  			RotatedRect rrt = minAreaRect(contours[index]);
  			ellipse(frame, rrt, Scalar(255, 50, 100), 2, 8);
  			circle(frame, rrt.center, 4, Scalar(50, 200, 50), 2, 8, 0);
  		}
  		imshow("output", frame);
  		char k = waitKey(100);
  		if (k == (int)"q") {
  			break;
  		}
  	}
  	destroyAllWindows();
  	capture.release();
  }
  ```

### 35.背景分析

+ ```c++
  /*
  背景提取、前景mask
  常见算法
  	KNN
      GMM
      Fuzzy Integral
  基本流程
  	背景初始化阶段
  	前景检测阶段
  	背景更新/维护
  */
  // 建模， 背景分析方法
  // 1.用于训练背景的帧数，默认帧数为500帧, 2.方差阈值，用于判断当前像素是前景还是背景。一般默认为16，如果光照变化明显，如阳光下的水面，建议设为25，值越大灵敏度越低。3.是否检测影子，设为true为检测，false为不检测，检测影子会增加程序时间复杂度，一般设置为false；
  auto pMOG2 = createBackgroundSubtractorMOG2(500, 100, false);
  void fore_back_demo() {
  	VideoCapture capture("D:/images/vtest.avi");
  	Mat frame;
  	while (true) {
  		bool ret = capture.read(frame);
  		if (!ret) break;
  		imshow("input", frame);
  
  		Mat bg_image, mask;
  		// 得到前景mask
  		pMOG2->apply(frame, mask);
  		// 得到背景图像
  		pMOG2->getBackgroundImage(bg_image);
  		imshow("mask", mask);
  		imshow("bg image", bg_image);
  		char c = waitKey(10);
  		if (c == int('q')) {
  			break;
  		}
  	}
  	capture.release();
  	destroyAllWindows();
  
  }
  void fore_back_demo2() {
  	VideoCapture capture("D:/images/vtest.avi");
  	Mat frame;
  	while (true) {
  		bool ret = capture.read(frame);
  		if (!ret) break;
  		imshow("input", frame);
  
  		Mat bg_image, mask;
  		// 得到前景mask
  		pMOG2->apply(frame, mask);
  		imshow("mask", mask);
  
  		// 构造形态学使用的kernel
  		Mat se = getStructuringElement(MORPH_RECT, Size(1, 5), Point(-1, -1));
  		// 使用形态学的开运算做背景的去除
          morphologyEx(mask,mask, MORPH_OPEN, se);
  		imshow("output", mask);
  		
  		//在mask基础上发现轮廓
  		vector<vector<Point>>contours;
  		vector<Vec4i>hirearchy;
  		findContours(mask, contours, hirearchy, RETR_EXTERNAL, CHAIN_APPROX_SIMPLE, Point());
  		for (size_t t = 0; t < contours.size(); t++) {
  			double area = contourArea(contours[t]);
  			if (area < 100) continue;
              // 计算外接矩形, 不是斜的
  			Rect box = boundingRect(contours[t]);
              // 计算最小外接斜矩形
  			RotatedRect rrt = minAreaRect(contours[t]);
  			//rectangle(frame, box, Scalar(100, 200, 150), 2, 8, 0);
  			circle(frame, rrt.center, 2, Scalar(200, 100, 50), 2, 8, 0);
  			ellipse(frame, rrt, Scalar(50, 150, 100), 2, 8);
  		}
  		imshow("output", frame);
  		char c = waitKey(10);
  		if (c == int('q')) {
  			break;
  		}
  	}
  	capture.release();
  	destroyAllWindows();
  
  }
  ```

### 36.基于光流法的视频分析

+ ```c++
  /*
  稀疏光流分析
  	KLT光流分析原理
  		光亮恒定
  		近距离移动
  		空间一致行
  稠密光流法
  	坐标转换
  	对每个像素都计算移动距离
  	基于总位移与均值评估
  */
  // 稀疏光流法
  void klt_demo() {
  	VideoCapture capture("D:/images/balltest.mp4");
  	Mat old_frame, old_gray;
  	capture.read(old_frame);
  	cvtColor(old_frame, old_gray, COLOR_BGR2GRAY);
  	vector<Point2f>feature_pts;
  	vector<Point2f>initPoints;
  	double quality_level = 0.01;
  	int minDistance = 10;
      // shi-tomasi角点检测
  	goodFeaturesToTrack(old_gray, feature_pts, 100, quality_level, minDistance, Mat(), 3, false);
  	Mat frame, gray;
  	vector<Point2f>pts[2];
  	pts[0].insert(pts[0].end(), feature_pts.begin(), feature_pts.end());
  	initPoints.insert(initPoints.end(), feature_pts.begin(), feature_pts.end());
  	vector<uchar>status;
  	vector<float>err;
      // TermCriteria构造函数
      // COUNT迭代到最大迭代次数终止，EPS迭代到阈值终止，10为迭代的最大次数，阈值(中心位移值)
  	TermCriteria criteria = TermCriteria(TermCriteria::COUNT + TermCriteria::EPS, 10, 0.01);
  
  	while (true) {
  		bool ret = capture.read(frame);
  		if (!ret) break;
  		imshow("input", frame);
  
  		cvtColor(frame, gray, COLOR_BGR2GRAY);
  
  		// 计算光流
          // old_gray前一帧单通道图像，gray当前帧单通道图像，pts[0]需要找到流的2D点的矢量，pts[1]输出二维点的矢量，status输出状态向量(如果找到相应特征的流，则向量的每个元素设置为1，否则设置为0),err输出错误的矢量,Size搜索窗口的winSize大小, 3基于0的最大金字塔等级数, criteria指定迭代搜索算法的终止条件, 0操作标志
  		calcOpticalFlowPyrLK(old_gray, gray, pts[0], pts[1], status, err, Size(100, 100), 3, criteria, 0);
  		int k = 0;
  		RNG rng(12345);
  		for (int i = 0; i < pts[1].size(); i++) {
  			double dist = abs(pts[0][i].x - pts[1][i].x) + abs(pts[0][i].y - pts[1][i].y);
  			// 距离与状态检测
  			if (status[i] && dist > 2) {
  				initPoints[k] = initPoints[i];
  				pts[0][k] = pts[0][i];
  				pts[0][k++] = pts[1][i];
  				int b = rng.uniform(0, 255);
  				int g = rng.uniform(0, 255);
  				int r = rng.uniform(0, 255);
  				circle(frame, pts[1][i],2, Scalar(b, g, r), 2, 8, 0);
  				//line(frame, pts[0][i], pts[1][i], Scalar(b, g, r), 2, 8, 0);
  			}
  		}
  
  		// 更新关键点
  		pts[0].resize(k);
  		pts[1].resize(k);
  		initPoints.resize(k);
  
  		// 绘制跟踪线
  		draw_lines(frame, initPoints, pts[1]);
  
  		// 绘制跟踪
  		imshow("KLT-demo", frame);
  
  		// 更新旧的
  		std::swap(pts[1], pts[0]);
  		cv::swap(old_gray, gray);
  
  		// 重新初始化
  		if (pts[0].size() < 10) {
  			goodFeaturesToTrack(old_gray, feature_pts, 100, quality_level, minDistance, Mat(), 3, false);
  			pts[0].insert(pts[0].end(), feature_pts.begin(), feature_pts.end());
  			initPoints.insert(initPoints.end(), feature_pts.begin(), feature_pts.end());
  		}
  		
  		char c = waitKey(10);
  		if (c == int('q')) {
  			break;
  		}
  	}
  	capture.release();
  	destroyAllWindows();
  }
  
  void draw_lines(Mat &frame, vector<Point2f>pts1, vector<Point2f>pts2) {
  	RNG rng(12345);
  	vector<Scalar>lut;
  	for (size_t t = 0; t < pts1.size(); t++) {
  		int b = rng.uniform(0, 255);
  		int g = rng.uniform(0, 255);
  		int r = rng.uniform(0, 255);
  		lut.push_back(Scalar(b, g, r));
  	}
  	for (size_t t = 0; t < pts1.size(); t++) {
  		line(frame, pts1[t], pts2[t], lut[t], 2, 8, 0);
  	}
  }
  // 稠密光流法
  void choumi() {
  	VideoCapture capture("D:/images/vtest.avi");
  	if (!capture.isOpened()) {
  		printf("could not open the camera...\n");
  	}
  
  	Mat frame, preFrame;
  	Mat gray, preGray;
  	capture.read(preFrame);
  	cvtColor(preFrame, preGray, COLOR_BGR2GRAY);
  	Mat hsv = Mat::zeros(preFrame.size(), preFrame.type());
  	Mat mag = Mat::zeros(hsv.size(), CV_32FC1);
  	Mat ang = Mat::zeros(hsv.size(), CV_32FC1);
  	Mat xpts = Mat::zeros(hsv.size(), CV_32FC1);
  	Mat ypts = Mat::zeros(hsv.size(), CV_32FC1);
  	Mat_<Point2f>flow;
  	vector<Mat>mv;
  	split(hsv, mv);
  	Mat bgr;
  	while (true) {
  		bool ret = capture.read(frame);
  		if (!ret) break;
  		cvtColor(frame, gray, COLOR_BGR2GRAY);
  		// 稠密光流法: 
          // flow输出的光流信息，金字塔上下两层之间的尺度关系 默认为0.5表示图像金字塔上一层是下一层的2倍降采样
          // 3图像金字塔的层数，15均值窗口大小 winsize越大，算法对图像噪声越鲁棒，并且能提升对快速运动目标的检测效果，但也会引起运动区域模糊
          // 3算法在图像金字塔每层的迭代次数, 5用于在每个像素点处计算多项式展开的相邻像素点的个数
          // 1.2标准差, 0操作标记
  		calcOpticalFlowFarneback(preGray, gray, flow, 0.5, 3, 15, 3, 5, 1.2, 0);
  		for (int row = 0; row < flow.rows; row++) {
  			for (int col = 0; col < flow.cols; col++) {
  				const Point2f& flow_xy = flow.at<Point2f>(row, col);
  				xpts.at<float>(row, col) = flow_xy.x;
  				ypts.at<float>(row, col) = flow_xy.y;
  			}
  		}
          // 作用1：根据勾股定理求出另一条边的长度和三角形的角度（y/x=tan α）。
  		// 作用2：取梯度幅值和方向。先用sobel求出水平和垂直方向的梯度，再用cartToPolar求出梯度幅值和方向。
  		cartToPolar(xpts, ypts, mag, ang);
  		ang = ang * 180 / CV_PI / 2.0;
  		normalize(mag, mag, 0, 255, NORM_MINMAX);
  		// 取绝对值，并且转换为8位的字节
  		convertScaleAbs(mag, mag);
  		convertScaleAbs(ang, ang);
  
  		mv[0] = ang;
  		mv[1] = Scalar(255);
  		mv[2] = mag;
  		merge(mv, hsv);
  		cvtColor(hsv, bgr, COLOR_HSV2BGR);
  
  		imshow("frame", frame);
  		imshow("result", bgr);
  
  		char c = waitKey(10);
  		if (c == int('q')) {
  			break;
  		}
  	}
  	capture.release();
  }
  ```

### 37.基于均值迁移的视频分析

+ ```c++
  /*
  MeanShift/CA-MeanShift
  */
  void xxx() {
  	VideoCapture capture("D:/images/balltest.mp4");
  	if (!capture.isOpened()) {
  		printf("could not open the camera...\n");
  	}
  	Mat frame, hsv, hue, mask, hist, backproj;
  	capture.read(frame);
      // 可以让用户框出感兴趣的区域，以便对这个区域进行截取和后续处理
      // 输出选定区域的bbox：（minx, miny, w, h）。即左上角坐标和w、h
  	Rect selection = selectROI("MeanShift Demo", frame, true, false);
  	Rect trackWindow;
  	int hsize = 16;
  	float hranges[] = { 0, 180 };
  	bool init = true;
  	const float* ranges = hranges;
  	while (true) {
  		bool ret = capture.read(frame);
  		if (!ret)break;
  		imshow("frame", frame);
  		cvtColor(frame, hsv, COLOR_BGR2HSV);
  
  		inRange(hsv, Scalar(26, 43, 46), Scalar(34, 255, 255), mask);
  		int ch[] = { 0, 0 };
          // 创建空矩阵
  		hue.create(hsv.size(), hsv.depth());
          // 用于将输入数组的指定通道复制到输出数组的指定通道
  		mixChannels(&hsv, 1, &hue, 1, ch, 1);
  		
  		if (init) {
  			Mat roi(hue, selection), maskroi(mask, selection);
  			calcHist(&roi, 1, 0, maskroi, hist, 1, &hsize, &ranges);
  			normalize(hist, hist, 0, 255, NORM_MINMAX);
  			trackWindow = selection;
  			init = false;
  		}
  		calcBackProject(&hue, 1, 0, hist, backproj, &ranges);
  		
  		backproj &= mask;
  		// ms meanshift算法，获得搜索窗新的大小和位置
  		//meanShift(backproj, trackWindow, TermCriteria(TermCriteria::COUNT | TermCriteria::EPS, 10, 1));
  		//rectangle(frame, trackWindow, Scalar(0, 0, 255), 3, LINE_AA);
  		
  		// 自适应ms CamShift目标跟踪算法, 能有效解决目标变形和遮挡的问题
  		RotatedRect rrt = CamShift(backproj, trackWindow, TermCriteria(TermCriteria::COUNT | TermCriteria::EPS, 10, 1));
  		ellipse(frame, rrt, Scalar(255, 0, 0), 2, 8);
  		
  		imshow("CAMeanShift Demo", frame);
  
  		char c = waitKey(10);
  		if (c == int('q')) {
  			break;
  		}
  	}
  	capture.release();
  	destroyAllWindows();
  }
  ```
  
  

